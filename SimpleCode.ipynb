{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILD CHATGPT KIND OF SYSTEM FROM SCRATCH -\n",
        "\n",
        "BUT start from basics\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IG-786eN6Yws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, you will learn how to create linear model, binary classification and character level prediction model without any fancy language transformer"
      ],
      "metadata": {
        "id": "h_h-7tzPWuVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## example of linear regression using pytorch ###"
      ],
      "metadata": {
        "id": "zpgUeZUzRdyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Simple linear model\n",
        "model = nn.Linear(1, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "y = torch.tensor([[2.0], [4.0], [6.0]])\n",
        "\n",
        "for epoch in range(100):\n",
        "    pred = model(x)\n",
        "    loss = criterion(pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "_DIl7Wo5RLbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([[4.0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaYWptKRTxQ",
        "outputId": "4cd925cd-85bb-4715-9f1b-334bc2981a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.4299]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ombK1l6gRZQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## end of linear model example ###"
      ],
      "metadata": {
        "id": "E5HhC0kpRZ1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of binary classification *model*"
      ],
      "metadata": {
        "id": "eAu7L32pSrMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulated output from a model for a single input\n",
        "logits = torch.tensor([2.0, 0.5])  # Raw scores for [cat, dog]\n",
        "\n",
        "# Apply softmax to convert logits to probabilities\n",
        "probs = F.softmax(logits, dim=0)\n",
        "\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRz6FEf8SsNN",
        "outputId": "32b61412-0158-474b-c8cf-ae2ba0440f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([2.0000, 0.5000])\n",
            "Probabilities: tensor([0.8176, 0.1824])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End of binary classification model"
      ],
      "metadata": {
        "id": "S7AIbRsuSsr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## example of language model - character level prediction model ##"
      ],
      "metadata": {
        "id": "lS82vb8WRq6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Ad7zlpN4RT6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hello\"\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcnUMHlL6CHl",
        "outputId": "e91cb91b-d3b7-4f7c-fcae-cf776b2f37e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['e', 'h', 'l', 'o']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for ch,i in stoi.items() }\n",
        "\n",
        "# Encode and decode functions\n",
        "def encode(s): return [stoi[c] for c in s]\n",
        "def decode(l): return ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "sbH5qVZK6odc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"hello\" ‚Üí input: \"h\", \"e\", \"l\", \"l\" ‚Üí target: \"e\", \"l\", \"l\", \"o\"\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "x = data[:-1].unsqueeze(0)  # shape (1, 4)\n",
        "y = data[1:].unsqueeze(0)   # shape (1, 4)\n"
      ],
      "metadata": {
        "id": "EXOE7WtN6FCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nztwKwQ6907",
        "outputId": "cfa0c4cc-8996-45ef-9162-77fc4164a74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfqkOddq9kx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BIGRAM MODEL\n",
        "\n",
        "A bigram model is a type of statistical language model in natural language processing (NLP) that predicts the likelihood of a word based on the word that comes immediately before it. It‚Äôs a simple yet powerful way to capture short-range word dependencies in text.\n",
        "\n"
      ],
      "metadata": {
        "id": "S6tnNd1agSpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence: ‚ÄúI love programming languages‚Äù Bigrams: (‚ÄúI‚Äù, ‚Äúlove‚Äù), (‚Äúlove‚Äù, ‚Äúprogramming‚Äù), (‚Äúprogramming‚Äù, ‚Äúlanguages‚Äù) Probability: $\n",
        "ùëÉ\n",
        "(\n",
        "\"\n",
        "ùêº\n",
        "\"\n",
        ")\n",
        "√ó\n",
        "ùëÉ\n",
        "(\n",
        "\"\n",
        "ùëô\n",
        "ùëú\n",
        "ùë£\n",
        "ùëí\n",
        "\"\n",
        "‚à£\n",
        "\"\n",
        "ùêº\n",
        "\"\n",
        ")\n",
        "√ó\n",
        "ùëÉ\n",
        "(\n",
        "\"\n",
        "ùëù\n",
        "ùëü\n",
        "ùëú\n",
        "ùëî\n",
        "ùëü\n",
        "ùëé\n",
        "ùëö\n",
        "ùëö\n",
        "ùëñ\n",
        "ùëõ\n",
        "ùëî\n",
        "\"\n",
        "‚à£\n",
        "\"\n",
        "ùëô\n",
        "ùëú\n",
        "ùë£\n",
        "ùëí\n",
        "\"\n",
        ")\n",
        "√ó\n",
        "ùëÉ\n",
        "(\n",
        "\"\n",
        "ùëô\n",
        "ùëé\n",
        "ùëõ\n",
        "ùëî\n",
        "ùë¢\n",
        "ùëé\n",
        "ùëî\n",
        "ùëí\n",
        "ùë†\n",
        "\"\n",
        "‚à£\n",
        "\"\n",
        "ùëù\n",
        "ùëü\n",
        "ùëú\n",
        "ùëî\n",
        "ùëü\n",
        "ùëé\n",
        "ùëö\n",
        "ùëö\n",
        "ùëñ\n",
        "ùëõ\n",
        "ùëî\n",
        "\"\n",
        ")\n",
        "$"
      ],
      "metadata": {
        "id": "scjM1zFLgu1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "self.token_embedding_table(idx) returns a tensor of shape (B, T, C):\n",
        "\n",
        "B = batch size\n",
        "T = sequence length\n",
        "C = number of classes or vocabulary size (i.e., the dimension of the embedding)"
      ],
      "metadata": {
        "id": "VRHe38QCVjXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            print(\"Logits:\", logits)\n",
        "            print(\"targets:\", targets)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n"
      ],
      "metadata": {
        "id": "Uf4qywiX6JVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel(vocab_size)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Ensure inputs are of type LongTensor\n",
        "x = x.long()\n",
        "y = y.long()\n",
        "\n",
        "for step in range(100):\n",
        "    logits, loss = model(x, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdCD5G-a6Llc",
        "outputId": "91f0debd-c7a4-4de1-cfb3-224f75ff3a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[ 0.5382, -0.7925, -2.6604,  0.4119],\n",
            "        [-0.9059, -0.7910,  0.0617, -0.5902],\n",
            "        [ 0.3625,  1.0737,  1.6481, -0.1337],\n",
            "        [ 0.3625,  1.0737,  1.6481, -0.1337]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 0, Loss: 1.2007\n",
            "Logits: tensor([[ 0.5482, -0.8024, -2.6701,  0.4018],\n",
            "        [-0.9158, -0.8009,  0.0717, -0.6001],\n",
            "        [ 0.3524,  1.0635,  1.6580, -0.1237],\n",
            "        [ 0.3524,  1.0635,  1.6580, -0.1237]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.5581, -0.8123, -2.6798,  0.3918],\n",
            "        [-0.9257, -0.8108,  0.0817, -0.6101],\n",
            "        [ 0.3424,  1.0534,  1.6567, -0.1137],\n",
            "        [ 0.3424,  1.0534,  1.6567, -0.1137]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.5681, -0.8222, -2.6896,  0.3818],\n",
            "        [-0.9356, -0.8207,  0.0917, -0.6200],\n",
            "        [ 0.3324,  1.0433,  1.6510, -0.1037],\n",
            "        [ 0.3324,  1.0433,  1.6510, -0.1037]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.5780, -0.8321, -2.6993,  0.3717],\n",
            "        [-0.9455, -0.8306,  0.1017, -0.6299],\n",
            "        [ 0.3224,  1.0333,  1.6437, -0.0937],\n",
            "        [ 0.3224,  1.0333,  1.6437, -0.0937]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.5879, -0.8420, -2.7090,  0.3617],\n",
            "        [-0.9554, -0.8405,  0.1116, -0.6398],\n",
            "        [ 0.3123,  1.0232,  1.6356, -0.0837],\n",
            "        [ 0.3123,  1.0232,  1.6356, -0.0837]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.5978, -0.8519, -2.7187,  0.3517],\n",
            "        [-0.9653, -0.8504,  0.1216, -0.6498],\n",
            "        [ 0.3023,  1.0131,  1.6270, -0.0737],\n",
            "        [ 0.3023,  1.0131,  1.6270, -0.0737]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6077, -0.8618, -2.7284,  0.3417],\n",
            "        [-0.9751, -0.8603,  0.1316, -0.6597],\n",
            "        [ 0.2923,  1.0030,  1.6182, -0.0637],\n",
            "        [ 0.2923,  1.0030,  1.6182, -0.0637]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6176, -0.8716, -2.7381,  0.3318],\n",
            "        [-0.9850, -0.8701,  0.1415, -0.6695],\n",
            "        [ 0.2823,  0.9929,  1.6095, -0.0537],\n",
            "        [ 0.2823,  0.9929,  1.6095, -0.0537]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6275, -0.8815, -2.7477,  0.3218],\n",
            "        [-0.9948, -0.8800,  0.1514, -0.6794],\n",
            "        [ 0.2723,  0.9828,  1.6010, -0.0437],\n",
            "        [ 0.2723,  0.9828,  1.6010, -0.0437]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6373, -0.8913, -2.7574,  0.3118],\n",
            "        [-1.0046, -0.8898,  0.1613, -0.6893],\n",
            "        [ 0.2623,  0.9728,  1.5931, -0.0337],\n",
            "        [ 0.2623,  0.9728,  1.5931, -0.0337]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 10, Loss: 1.1069\n",
            "Logits: tensor([[ 0.6472, -0.9011, -2.7670,  0.3019],\n",
            "        [-1.0144, -0.8996,  0.1712, -0.6991],\n",
            "        [ 0.2523,  0.9627,  1.5857, -0.0238],\n",
            "        [ 0.2523,  0.9627,  1.5857, -0.0238]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6570, -0.9109, -2.7766,  0.2920],\n",
            "        [-1.0242, -0.9094,  0.1811, -0.7089],\n",
            "        [ 0.2423,  0.9527,  1.5790, -0.0138],\n",
            "        [ 0.2423,  0.9527,  1.5790, -0.0138]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6668, -0.9207, -2.7862,  0.2821],\n",
            "        [-1.0340, -0.9192,  0.1909, -0.7187],\n",
            "        [ 0.2324,  0.9426,  1.5731, -0.0039],\n",
            "        [ 0.2324,  0.9426,  1.5731, -0.0039]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6765, -0.9304, -2.7957,  0.2723],\n",
            "        [-1.0437, -0.9290,  0.2007, -0.7285],\n",
            "        [ 0.2224,  0.9326,  1.5678,  0.0061],\n",
            "        [ 0.2224,  0.9326,  1.5678,  0.0061]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6863, -0.9401, -2.8053,  0.2624],\n",
            "        [-1.0534, -0.9387,  0.2105, -0.7382],\n",
            "        [ 0.2124,  0.9225,  1.5630,  0.0160],\n",
            "        [ 0.2124,  0.9225,  1.5630,  0.0160]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.6960, -0.9498, -2.8148,  0.2526],\n",
            "        [-1.0631, -0.9484,  0.2203, -0.7479],\n",
            "        [ 0.2025,  0.9125,  1.5585,  0.0259],\n",
            "        [ 0.2025,  0.9125,  1.5585,  0.0259]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7057, -0.9595, -2.8243,  0.2428],\n",
            "        [-1.0728, -0.9581,  0.2301, -0.7576],\n",
            "        [ 0.1925,  0.9025,  1.5541,  0.0358],\n",
            "        [ 0.1925,  0.9025,  1.5541,  0.0358]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7153, -0.9691, -2.8337,  0.2331],\n",
            "        [-1.0824, -0.9677,  0.2398, -0.7673],\n",
            "        [ 0.1826,  0.8925,  1.5496,  0.0457],\n",
            "        [ 0.1826,  0.8925,  1.5496,  0.0457]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7250, -0.9787, -2.8431,  0.2234],\n",
            "        [-1.0920, -0.9773,  0.2495, -0.7769],\n",
            "        [ 0.1727,  0.8826,  1.5448,  0.0556],\n",
            "        [ 0.1727,  0.8826,  1.5448,  0.0556]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7346, -0.9883, -2.8525,  0.2137],\n",
            "        [-1.1016, -0.9869,  0.2591, -0.7865],\n",
            "        [ 0.1628,  0.8726,  1.5398,  0.0655],\n",
            "        [ 0.1628,  0.8726,  1.5398,  0.0655]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 20, Loss: 1.0206\n",
            "Logits: tensor([[ 0.7441, -0.9978, -2.8619,  0.2040],\n",
            "        [-1.1112, -0.9965,  0.2688, -0.7961],\n",
            "        [ 0.1529,  0.8626,  1.5344,  0.0753],\n",
            "        [ 0.1529,  0.8626,  1.5344,  0.0753]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7536, -1.0073, -2.8712,  0.1944],\n",
            "        [-1.1207, -1.0060,  0.2784, -0.8057],\n",
            "        [ 0.1431,  0.8527,  1.5288,  0.0851],\n",
            "        [ 0.1431,  0.8527,  1.5288,  0.0851]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7631, -1.0168, -2.8805,  0.1848],\n",
            "        [-1.1301, -1.0155,  0.2879, -0.8152],\n",
            "        [ 0.1332,  0.8428,  1.5229,  0.0950],\n",
            "        [ 0.1332,  0.8428,  1.5229,  0.0950]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7726, -1.0262, -2.8897,  0.1753],\n",
            "        [-1.1396, -1.0249,  0.2974, -0.8246],\n",
            "        [ 0.1234,  0.8329,  1.5169,  0.1048],\n",
            "        [ 0.1234,  0.8329,  1.5169,  0.1048]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7820, -1.0356, -2.8989,  0.1658],\n",
            "        [-1.1490, -1.0343,  0.3069, -0.8341],\n",
            "        [ 0.1136,  0.8230,  1.5109,  0.1145],\n",
            "        [ 0.1136,  0.8230,  1.5109,  0.1145]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.7913, -1.0449, -2.9081,  0.1563],\n",
            "        [-1.1583, -1.0437,  0.3164, -0.8434],\n",
            "        [ 0.1038,  0.8131,  1.5051,  0.1243],\n",
            "        [ 0.1038,  0.8131,  1.5051,  0.1243]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8007, -1.0542, -2.9172,  0.1469],\n",
            "        [-1.1676, -1.0530,  0.3258, -0.8528],\n",
            "        [ 0.0940,  0.8033,  1.4995,  0.1341],\n",
            "        [ 0.0940,  0.8033,  1.4995,  0.1341]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8099, -1.0635, -2.9263,  0.1376],\n",
            "        [-1.1769, -1.0623,  0.3351, -0.8621],\n",
            "        [ 0.0842,  0.7935,  1.4942,  0.1438],\n",
            "        [ 0.0842,  0.7935,  1.4942,  0.1438]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8192, -1.0727, -2.9354,  0.1282],\n",
            "        [-1.1862, -1.0716,  0.3444, -0.8714],\n",
            "        [ 0.0745,  0.7837,  1.4894,  0.1535],\n",
            "        [ 0.0745,  0.7837,  1.4894,  0.1535]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8284, -1.0819, -2.9444,  0.1189],\n",
            "        [-1.1954, -1.0808,  0.3537, -0.8806],\n",
            "        [ 0.0648,  0.7739,  1.4848,  0.1632],\n",
            "        [ 0.0648,  0.7739,  1.4848,  0.1632]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 30, Loss: 0.9427\n",
            "Logits: tensor([[ 0.8375, -1.0910, -2.9533,  0.1097],\n",
            "        [-1.2045, -1.0899,  0.3630, -0.8898],\n",
            "        [ 0.0551,  0.7641,  1.4806,  0.1728],\n",
            "        [ 0.0551,  0.7641,  1.4806,  0.1728]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8466, -1.1001, -2.9622,  0.1005],\n",
            "        [-1.2136, -1.0991,  0.3722, -0.8989],\n",
            "        [ 0.0454,  0.7544,  1.4767,  0.1825],\n",
            "        [ 0.0454,  0.7544,  1.4767,  0.1825]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8557, -1.1091, -2.9711,  0.0914],\n",
            "        [-1.2227, -1.1081,  0.3813, -0.9080],\n",
            "        [ 0.0357,  0.7446,  1.4729,  0.1921],\n",
            "        [ 0.0357,  0.7446,  1.4729,  0.1921]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8647, -1.1181, -2.9799,  0.0823],\n",
            "        [-1.2317, -1.1172,  0.3904, -0.9171],\n",
            "        [ 0.0261,  0.7349,  1.4691,  0.2017],\n",
            "        [ 0.0261,  0.7349,  1.4691,  0.2017]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8736, -1.1271, -2.9887,  0.0732],\n",
            "        [-1.2407, -1.1262,  0.3995, -0.9261],\n",
            "        [ 0.0165,  0.7252,  1.4652,  0.2113],\n",
            "        [ 0.0165,  0.7252,  1.4652,  0.2113]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.8826, -1.1360, -2.9974,  0.0642],\n",
            "        [-1.2496, -1.1351,  0.4085, -0.9350],\n",
            "        [ 0.0069,  0.7156,  1.4613,  0.2208],\n",
            "        [ 0.0069,  0.7156,  1.4613,  0.2208]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 8.9141e-01, -1.1448e+00, -3.0061e+00,  5.5254e-02],\n",
            "        [-1.2585e+00, -1.1440e+00,  4.1743e-01, -9.4393e-01],\n",
            "        [-2.6770e-03,  7.0596e-01,  1.4572e+00,  2.3038e-01],\n",
            "        [-2.6770e-03,  7.0596e-01,  1.4572e+00,  2.3038e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9002, -1.1536, -3.0147,  0.0464],\n",
            "        [-1.2673, -1.1528,  0.4263, -0.9528],\n",
            "        [-0.0122,  0.6964,  1.4530,  0.2399],\n",
            "        [-0.0122,  0.6964,  1.4530,  0.2399]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9090, -1.1624, -3.0233,  0.0375],\n",
            "        [-1.2761, -1.1616,  0.4352, -0.9616],\n",
            "        [-0.0217,  0.6868,  1.4488,  0.2494],\n",
            "        [-0.0217,  0.6868,  1.4488,  0.2494]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9177, -1.1710, -3.0318,  0.0287],\n",
            "        [-1.2848, -1.1704,  0.4440, -0.9704],\n",
            "        [-0.0312,  0.6772,  1.4446,  0.2588],\n",
            "        [-0.0312,  0.6772,  1.4446,  0.2588]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 40, Loss: 0.8734\n",
            "Logits: tensor([[ 0.9264, -1.1797, -3.0403,  0.0199],\n",
            "        [-1.2935, -1.1791,  0.4528, -0.9791],\n",
            "        [-0.0407,  0.6677,  1.4404,  0.2682],\n",
            "        [-0.0407,  0.6677,  1.4404,  0.2682]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9350, -1.1883, -3.0487,  0.0113],\n",
            "        [-1.3022, -1.1877,  0.4615, -0.9877],\n",
            "        [-0.0501,  0.6582,  1.4364,  0.2776],\n",
            "        [-0.0501,  0.6582,  1.4364,  0.2776]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 9.4352e-01, -1.1968e+00, -3.0571e+00,  2.6036e-03],\n",
            "        [-1.3107e+00, -1.1963e+00,  4.7018e-01, -9.9635e-01],\n",
            "        [-5.9541e-02,  6.4872e-01,  1.4326e+00,  2.8702e-01],\n",
            "        [-5.9541e-02,  6.4872e-01,  1.4326e+00,  2.8702e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9520, -1.2053, -3.0654, -0.0060],\n",
            "        [-1.3193, -1.2048,  0.4788, -1.0049],\n",
            "        [-0.0689,  0.6393,  1.4291,  0.2964],\n",
            "        [-0.0689,  0.6393,  1.4291,  0.2964]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9605, -1.2138, -3.0737, -0.0145],\n",
            "        [-1.3278, -1.2133,  0.4874, -1.0134],\n",
            "        [-0.0783,  0.6299,  1.4258,  0.3057],\n",
            "        [-0.0783,  0.6299,  1.4258,  0.3057]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9689, -1.2221, -3.0819, -0.0230],\n",
            "        [-1.3362, -1.2218,  0.4959, -1.0219],\n",
            "        [-0.0876,  0.6205,  1.4227,  0.3150],\n",
            "        [-0.0876,  0.6205,  1.4227,  0.3150]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9772, -1.2305, -3.0901, -0.0315],\n",
            "        [-1.3446, -1.2302,  0.5043, -1.0303],\n",
            "        [-0.0969,  0.6111,  1.4198,  0.3242],\n",
            "        [-0.0969,  0.6111,  1.4198,  0.3242]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9855, -1.2388, -3.0982, -0.0398],\n",
            "        [-1.3529, -1.2385,  0.5128, -1.0387],\n",
            "        [-0.1062,  0.6018,  1.4170,  0.3335],\n",
            "        [-0.1062,  0.6018,  1.4170,  0.3335]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 0.9938, -1.2470, -3.1063, -0.0482],\n",
            "        [-1.3612, -1.2468,  0.5211, -1.0470],\n",
            "        [-0.1154,  0.5925,  1.4142,  0.3427],\n",
            "        [-0.1154,  0.5925,  1.4142,  0.3427]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0020, -1.2552, -3.1143, -0.0565],\n",
            "        [-1.3694, -1.2551,  0.5294, -1.0552],\n",
            "        [-0.1246,  0.5832,  1.4115,  0.3518],\n",
            "        [-0.1246,  0.5832,  1.4115,  0.3518]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 50, Loss: 0.8122\n",
            "Logits: tensor([[ 1.0101, -1.2633, -3.1223, -0.0647],\n",
            "        [-1.3776, -1.2632,  0.5377, -1.0634],\n",
            "        [-0.1338,  0.5740,  1.4087,  0.3610],\n",
            "        [-0.1338,  0.5740,  1.4087,  0.3610]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0182, -1.2714, -3.1302, -0.0729],\n",
            "        [-1.3857, -1.2714,  0.5459, -1.0716],\n",
            "        [-0.1430,  0.5647,  1.4058,  0.3701],\n",
            "        [-0.1430,  0.5647,  1.4058,  0.3701]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0262, -1.2794, -3.1381, -0.0810],\n",
            "        [-1.3938, -1.2795,  0.5541, -1.0797],\n",
            "        [-0.1521,  0.5556,  1.4030,  0.3792],\n",
            "        [-0.1521,  0.5556,  1.4030,  0.3792]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0342, -1.2873, -3.1459, -0.0890],\n",
            "        [-1.4019, -1.2875,  0.5622, -1.0877],\n",
            "        [-0.1612,  0.5464,  1.4002,  0.3882],\n",
            "        [-0.1612,  0.5464,  1.4002,  0.3882]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0421, -1.2953, -3.1536, -0.0971],\n",
            "        [-1.4098, -1.2955,  0.5702, -1.0958],\n",
            "        [-0.1702,  0.5373,  1.3975,  0.3972],\n",
            "        [-0.1702,  0.5373,  1.3975,  0.3972]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0500, -1.3031, -3.1613, -0.1050],\n",
            "        [-1.4178, -1.3034,  0.5782, -1.1037],\n",
            "        [-0.1793,  0.5282,  1.3949,  0.4062],\n",
            "        [-0.1793,  0.5282,  1.3949,  0.4062]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0578, -1.3109, -3.1690, -0.1129],\n",
            "        [-1.4256, -1.3113,  0.5862, -1.1116],\n",
            "        [-0.1882,  0.5192,  1.3924,  0.4152],\n",
            "        [-0.1882,  0.5192,  1.3924,  0.4152]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0656, -1.3187, -3.1766, -0.1208],\n",
            "        [-1.4334, -1.3191,  0.5941, -1.1194],\n",
            "        [-0.1972,  0.5102,  1.3901,  0.4241],\n",
            "        [-0.1972,  0.5102,  1.3901,  0.4241]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0733, -1.3264, -3.1842, -0.1286],\n",
            "        [-1.4412, -1.3269,  0.6020, -1.1272],\n",
            "        [-0.2061,  0.5012,  1.3880,  0.4330],\n",
            "        [-0.2061,  0.5012,  1.3880,  0.4330]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0810, -1.3341, -3.1917, -0.1364],\n",
            "        [-1.4489, -1.3347,  0.6098, -1.1350],\n",
            "        [-0.2150,  0.4922,  1.3860,  0.4418],\n",
            "        [-0.2150,  0.4922,  1.3860,  0.4418]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 60, Loss: 0.7587\n",
            "Logits: tensor([[ 1.0886, -1.3417, -3.1991, -0.1441],\n",
            "        [-1.4566, -1.3423,  0.6175, -1.1427],\n",
            "        [-0.2239,  0.4833,  1.3842,  0.4506],\n",
            "        [-0.2239,  0.4833,  1.3842,  0.4506]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.0962, -1.3492, -3.2065, -0.1517],\n",
            "        [-1.4642, -1.3500,  0.6252, -1.1503],\n",
            "        [-0.2327,  0.4744,  1.3824,  0.4594],\n",
            "        [-0.2327,  0.4744,  1.3824,  0.4594]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1037, -1.3567, -3.2139, -0.1593],\n",
            "        [-1.4718, -1.3575,  0.6329, -1.1579],\n",
            "        [-0.2415,  0.4656,  1.3807,  0.4682],\n",
            "        [-0.2415,  0.4656,  1.3807,  0.4682]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1111, -1.3642, -3.2212, -0.1669],\n",
            "        [-1.4793, -1.3651,  0.6405, -1.1655],\n",
            "        [-0.2502,  0.4568,  1.3790,  0.4769],\n",
            "        [-0.2502,  0.4568,  1.3790,  0.4769]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1185, -1.3716, -3.2284, -0.1744],\n",
            "        [-1.4868, -1.3726,  0.6480, -1.1730],\n",
            "        [-0.2590,  0.4480,  1.3773,  0.4855],\n",
            "        [-0.2590,  0.4480,  1.3773,  0.4855]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1259, -1.3789, -3.2356, -0.1818],\n",
            "        [-1.4942, -1.3800,  0.6555, -1.1804],\n",
            "        [-0.2677,  0.4393,  1.3757,  0.4942],\n",
            "        [-0.2677,  0.4393,  1.3757,  0.4942]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1332, -1.3862, -3.2428, -0.1892],\n",
            "        [-1.5016, -1.3874,  0.6630, -1.1878],\n",
            "        [-0.2763,  0.4305,  1.3740,  0.5028],\n",
            "        [-0.2763,  0.4305,  1.3740,  0.5028]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1405, -1.3935, -3.2499, -0.1966],\n",
            "        [-1.5089, -1.3947,  0.6704, -1.1952],\n",
            "        [-0.2849,  0.4219,  1.3725,  0.5114],\n",
            "        [-0.2849,  0.4219,  1.3725,  0.5114]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1477, -1.4007, -3.2570, -0.2039],\n",
            "        [-1.5162, -1.4020,  0.6777, -1.2025],\n",
            "        [-0.2935,  0.4132,  1.3710,  0.5199],\n",
            "        [-0.2935,  0.4132,  1.3710,  0.5199]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1549, -1.4079, -3.2640, -0.2111],\n",
            "        [-1.5234, -1.4092,  0.6850, -1.2097],\n",
            "        [-0.3020,  0.4046,  1.3697,  0.5284],\n",
            "        [-0.3020,  0.4046,  1.3697,  0.5284]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 70, Loss: 0.7120\n",
            "Logits: tensor([[ 1.1620, -1.4150, -3.2709, -0.2183],\n",
            "        [-1.5306, -1.4164,  0.6923, -1.2169],\n",
            "        [-0.3105,  0.3961,  1.3684,  0.5368],\n",
            "        [-0.3105,  0.3961,  1.3684,  0.5368]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1690, -1.4220, -3.2778, -0.2255],\n",
            "        [-1.5377, -1.4235,  0.6995, -1.2241],\n",
            "        [-0.3190,  0.3876,  1.3673,  0.5453],\n",
            "        [-0.3190,  0.3876,  1.3673,  0.5453]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1761, -1.4290, -3.2847, -0.2326],\n",
            "        [-1.5448, -1.4306,  0.7067, -1.2312],\n",
            "        [-0.3274,  0.3791,  1.3664,  0.5537],\n",
            "        [-0.3274,  0.3791,  1.3664,  0.5537]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1830, -1.4360, -3.2915, -0.2396],\n",
            "        [-1.5518, -1.4377,  0.7138, -1.2382],\n",
            "        [-0.3358,  0.3706,  1.3655,  0.5620],\n",
            "        [-0.3358,  0.3706,  1.3655,  0.5620]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1900, -1.4429, -3.2983, -0.2466],\n",
            "        [-1.5588, -1.4447,  0.7208, -1.2452],\n",
            "        [-0.3442,  0.3622,  1.3646,  0.5703],\n",
            "        [-0.3442,  0.3622,  1.3646,  0.5703]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.1968, -1.4498, -3.3050, -0.2536],\n",
            "        [-1.5658, -1.4516,  0.7279, -1.2522],\n",
            "        [-0.3525,  0.3538,  1.3639,  0.5786],\n",
            "        [-0.3525,  0.3538,  1.3639,  0.5786]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2037, -1.4566, -3.3117, -0.2605],\n",
            "        [-1.5727, -1.4585,  0.7348, -1.2591],\n",
            "        [-0.3608,  0.3455,  1.3631,  0.5868],\n",
            "        [-0.3608,  0.3455,  1.3631,  0.5868]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2104, -1.4634, -3.3184, -0.2674],\n",
            "        [-1.5795, -1.4654,  0.7418, -1.2660],\n",
            "        [-0.3690,  0.3372,  1.3624,  0.5950],\n",
            "        [-0.3690,  0.3372,  1.3624,  0.5950]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2172, -1.4701, -3.3249, -0.2742],\n",
            "        [-1.5863, -1.4722,  0.7487, -1.2728],\n",
            "        [-0.3773,  0.3289,  1.3618,  0.6032],\n",
            "        [-0.3773,  0.3289,  1.3618,  0.6032]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2239, -1.4768, -3.3315, -0.2810],\n",
            "        [-1.5931, -1.4790,  0.7555, -1.2796],\n",
            "        [-0.3854,  0.3207,  1.3612,  0.6113],\n",
            "        [-0.3854,  0.3207,  1.3612,  0.6113]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 80, Loss: 0.6715\n",
            "Logits: tensor([[ 1.2305, -1.4835, -3.3380, -0.2877],\n",
            "        [-1.5998, -1.4857,  0.7623, -1.2864],\n",
            "        [-0.3936,  0.3125,  1.3606,  0.6194],\n",
            "        [-0.3936,  0.3125,  1.3606,  0.6194]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2371, -1.4901, -3.3445, -0.2944],\n",
            "        [-1.6064, -1.4924,  0.7690, -1.2930],\n",
            "        [-0.4017,  0.3044,  1.3602,  0.6274],\n",
            "        [-0.4017,  0.3044,  1.3602,  0.6274]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2437, -1.4966, -3.3509, -0.3011],\n",
            "        [-1.6131, -1.4990,  0.7757, -1.2997],\n",
            "        [-0.4097,  0.2963,  1.3598,  0.6355],\n",
            "        [-0.4097,  0.2963,  1.3598,  0.6355]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2502, -1.5031, -3.3572, -0.3077],\n",
            "        [-1.6197, -1.5056,  0.7824, -1.3063],\n",
            "        [-0.4177,  0.2882,  1.3595,  0.6434],\n",
            "        [-0.4177,  0.2882,  1.3595,  0.6434]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2567, -1.5096, -3.3636, -0.3142],\n",
            "        [-1.6262, -1.5121,  0.7890, -1.3129],\n",
            "        [-0.4257,  0.2802,  1.3593,  0.6514],\n",
            "        [-0.4257,  0.2802,  1.3593,  0.6514]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2631, -1.5160, -3.3698, -0.3207],\n",
            "        [-1.6327, -1.5186,  0.7956, -1.3194],\n",
            "        [-0.4336,  0.2722,  1.3592,  0.6592],\n",
            "        [-0.4336,  0.2722,  1.3592,  0.6592]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2695, -1.5224, -3.3761, -0.3272],\n",
            "        [-1.6391, -1.5251,  0.8021, -1.3258],\n",
            "        [-0.4415,  0.2642,  1.3592,  0.6671],\n",
            "        [-0.4415,  0.2642,  1.3592,  0.6671]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2758, -1.5287, -3.3823, -0.3336],\n",
            "        [-1.6455, -1.5315,  0.8086, -1.3323],\n",
            "        [-0.4494,  0.2563,  1.3592,  0.6749],\n",
            "        [-0.4494,  0.2563,  1.3592,  0.6749]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2821, -1.5350, -3.3884, -0.3400],\n",
            "        [-1.6519, -1.5379,  0.8150, -1.3387],\n",
            "        [-0.4572,  0.2484,  1.3593,  0.6827],\n",
            "        [-0.4572,  0.2484,  1.3593,  0.6827]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.2884, -1.5413, -3.3946, -0.3463],\n",
            "        [-1.6582, -1.5442,  0.8214, -1.3450],\n",
            "        [-0.4650,  0.2406,  1.3594,  0.6904],\n",
            "        [-0.4650,  0.2406,  1.3594,  0.6904]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Step 90, Loss: 0.6364\n",
            "Logits: tensor([[ 1.2946, -1.5475, -3.4006, -0.3526],\n",
            "        [-1.6645, -1.5505,  0.8278, -1.3513],\n",
            "        [-0.4728,  0.2328,  1.3595,  0.6981],\n",
            "        [-0.4728,  0.2328,  1.3595,  0.6981]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3008, -1.5537, -3.4067, -0.3589],\n",
            "        [-1.6707, -1.5567,  0.8341, -1.3576],\n",
            "        [-0.4805,  0.2250,  1.3597,  0.7058],\n",
            "        [-0.4805,  0.2250,  1.3597,  0.7058]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3069, -1.5598, -3.4127, -0.3651],\n",
            "        [-1.6769, -1.5630,  0.8404, -1.3638],\n",
            "        [-0.4882,  0.2173,  1.3599,  0.7134],\n",
            "        [-0.4882,  0.2173,  1.3599,  0.7134]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3130, -1.5659, -3.4186, -0.3713],\n",
            "        [-1.6831, -1.5691,  0.8466, -1.3700],\n",
            "        [-0.4958,  0.2096,  1.3602,  0.7210],\n",
            "        [-0.4958,  0.2096,  1.3602,  0.7210]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3191, -1.5719, -3.4245, -0.3774],\n",
            "        [-1.6892, -1.5752,  0.8528, -1.3761],\n",
            "        [-0.5034,  0.2020,  1.3606,  0.7285],\n",
            "        [-0.5034,  0.2020,  1.3606,  0.7285]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3251, -1.5779, -3.4304, -0.3835],\n",
            "        [-1.6953, -1.5813,  0.8590, -1.3822],\n",
            "        [-0.5109,  0.1944,  1.3611,  0.7360],\n",
            "        [-0.5109,  0.1944,  1.3611,  0.7360]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3310, -1.5839, -3.4363, -0.3896],\n",
            "        [-1.7013, -1.5874,  0.8651, -1.3883],\n",
            "        [-0.5184,  0.1868,  1.3616,  0.7435],\n",
            "        [-0.5184,  0.1868,  1.3616,  0.7435]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3370, -1.5898, -3.4421, -0.3956],\n",
            "        [-1.7073, -1.5934,  0.8712, -1.3943],\n",
            "        [-0.5259,  0.1793,  1.3622,  0.7509],\n",
            "        [-0.5259,  0.1793,  1.3622,  0.7509]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n",
            "Logits: tensor([[ 1.3429, -1.5957, -3.4478, -0.4016],\n",
            "        [-1.7133, -1.5994,  0.8772, -1.4003],\n",
            "        [-0.5334,  0.1718,  1.3628,  0.7583],\n",
            "        [-0.5334,  0.1718,  1.3628,  0.7583]], grad_fn=<ViewBackward0>)\n",
            "targets: tensor([0, 2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.tensor([[stoi['h']]], dtype=torch.long)\n",
        "\n",
        "generated = []\n",
        "for _ in range(10):\n",
        "    logits, _ = model(context)\n",
        "    probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "    next_token = torch.multinomial(probs, num_samples=1)\n",
        "    generated.append(next_token.item())\n",
        "    context = next_token\n",
        "\n",
        "print(\"Generated:\", decode(generated))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCAqId-06POV",
        "outputId": "c13e61ac-24e9-423f-fca7-e8601c939666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: elhelhelhe\n"
          ]
        }
      ]
    }
  ]
}